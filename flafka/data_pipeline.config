# Configure source, channel & sink
data_pipeline.sources = kafka-twitter
data_pipeline.channels = kafka-channel
data_pipeline.sinks = hdfs
# Configure source
data_pipeline.sources.kafka-twitter.type = org.apache.flume.source.kafka.KafkaSource
data_pipeline.sources.kafka-twitter.kafka.bootstrap.servers = broker:9092
data_pipeline.sources.kafka-twitter.kafka.topics = twitter
data_pipeline.sources.kafka-twitter.channels = kafka-channel
# Configure channel
data_pipeline.channels.kafka-channel.type = org.apache.flume.channel.kafka.KafkaChannel
data_pipeline.channels.kafka-channel.zookeeperConnect = zookeeper:2181
data_pipeline.channels.kafka-channel.capacity = 10000
data_pipeline.channels.kafka-channel.transactionCapacity = 100
data_pipeline.channels.kafka-channel.kafka.bootstrap.servers = broker:9092
data_pipeline.channels.kafka-channel.kafka.topic = channel
data_pipeline.channels.kafka-channel.parseAsFlumeEvent = false
# Configure sink
data_pipeline.sinks.hdfs.type = hdfs
data_pipeline.sinks.hdfs.hdfs.path = hdfs://namenode:8020/data
data_pipeline.sinks.hdfs.hdfs.rollInterval = 5
data_pipeline.sinks.hdfs.hdfs.rollSize = 0
data_pipeline.sinks.hdfs.hdfs.rollCount = 0
data_pipeline.sinks.hdfs.hdfs.fileType = DataStream
data_pipeline.sinks.hdfs.channel = kafka-channel
